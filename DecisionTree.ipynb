{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、计算给定数据的香农熵\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcShannonEnt(dataSet):\n",
    "    numEntries=len(dataSet)  #获得数据集的行数\n",
    "    labelCounts={}  #字典：key表示类标签，value表示在数据集中每个类标签出现的次数\n",
    "    for featVec in dataSet:   #以行为单位遍历数据集\n",
    "        currentLabel=featVec[-1]  #每一行的最后一个数据是该行数据的类标签\n",
    "        if currentLabel not in labelCounts.keys(): \n",
    "            labelCounts[currentLabel]=0\n",
    "        labelCounts[currentLabel]+=1\n",
    "    shannonEnt=0.0\n",
    "    for key in labelCounts:  #遍历字典的key，计算所有类别所有可能值包含的信息期望值\n",
    "        prob=float(labelCounts[key])/numEntries\n",
    "        shannonEnt-=prob*log(prob,2)\n",
    "    return shannonEnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、按照给定特征划分数据集\n",
    "dataSet --  待划分的数据集  \n",
    "axis -- 划分数据集的特征 （索引）   \n",
    "value -- 需要返回的特征的值  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataSet(dataSet,axis,value):\n",
    "    retDataSet=[]\n",
    "    for featVec in dataSet:  #遍历数据集的每一行\n",
    "        if featVec[axis] == value:  #若该行数据在axis索引位置上的值等于value，将该行数据在axis上的值剔除，并保存到列表中返回\n",
    "            reducedFeatVec=featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3、选择最好的数据集划分方式\n",
    "\n",
    "以海洋生物的数据为例：  \n",
    "1,1,'yes'  \n",
    "1,0,'yes'  \n",
    "1,0,'no'  \n",
    "0,1,'no'  \n",
    "0,1,'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chooseBestFeatureToSplit(dataSet):\n",
    "    numFeatures=len(dataSet[0])-1  #计算特征的数量，例子中为2，不包含最后一列的类标签\n",
    "    baseEntropy=calcShannonEnt(dataSet) #计算原始数据集的香农熵\n",
    "    bestInfoGain=0.0;bestFeature=-1\n",
    "    for i in range(numFeatures): #遍历特征，逐一选择最优划分数据集的特征\n",
    "        featList=[example[i] for example in dataSet]  #获得每一列的取值，即每个特征的取值\n",
    "        uniqueVals=set(featList) #对每个特征的取值去重，获得特征中的所有唯一属性值，例子中分别为：{0,1}和{0,1}\n",
    "        newEntropy=0.0\n",
    "        for value in uniqueVals:  #遍历特征的唯一属性值 \n",
    "            subDataSet=splitDataSet(dataSet,i,value) #以例子中第一个特征为例，第一次返回：[1,no],[1,no];第二次返回[1,yes],[0,yes],[0,no]\n",
    "            prob=len(subDataSet)/float(len(dataSet))\n",
    "            newEntropy+=prob*calcShannonEnt(subDataSet) #对所有唯一特征值得到的熵求和\n",
    "        infoGain=baseEntropy-newEntropy  #计算信息增益\n",
    "        if(infoGain>bestInfoGain):  #信息增益最大的就是划分数据集最好的特征\n",
    "            bestInfoGain=infoGain\n",
    "            bestFeature=i\n",
    "    return bestFeature  #返回最好特征的索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4、多数表决确定叶子节点的分类\n",
    "该方法用于，若数据集已经处理了所有的属性，但是类标签依然不是唯一的这种情况。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majorityCnt(classList):\n",
    "    classCount={}\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote]=0\n",
    "        classCount[vote]+=1\n",
    "    sortedClassCount=sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5、创建树\n",
    "dataSet -- 数据集  \n",
    "labels -- 标签列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTree(dataSet,labels):\n",
    "    classList=[example[-1] for example in dataSet]  #获得数据集的所有类标签\n",
    "    if classList.count(classList[0])==len(classList):  #递归结束的第一个条件：数据集的所有类标签完全相同\n",
    "        return classList[0]\n",
    "    if len(dataSet[0])==1: #递归结束的第二个条件：数据集的列数为1，即使用完了所有特征，仍不能将数据集划分为唯一的分组\n",
    "        return majorityCnt(classList) #采用多数表决法\n",
    "    bestFeat=chooseBestFeatureToSplit(dataSet)  #获得最好划分数据集的特征索引\n",
    "    bestFeatLabel=labels[bestFeat] #获得该特征的标签名\n",
    "    myTree={bestFeatLabel:{}}  #以字典的方式保存构建的决策树\n",
    "    del(labels[bestFeat])\n",
    "    featValues=[example[bestFeat] for example in dataSet]  #获得该数据集下该特征的所有取值\n",
    "    uniqueVals=set(featValues) #去重\n",
    "    for value in uniqueVals:\n",
    "        subLabels=labels[:]\n",
    "        myTree[bestFeatLabel][value]=createTree(splitDataSet(dataSet,bestFeat,value),subLabels) #递归调用\n",
    "    return myTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6、使用树\n",
    "inputTree -- 构建的决策树  \n",
    "featLabels -- 特征标签列表  \n",
    "testVec -- 册数数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(inputTree,featLabels,testVec):\n",
    "    #firstStr=inputTree.keys()[0] # 获得第一个划分数据集的特征\n",
    "    firstStr=list(inputTree.keys())[0]\n",
    "    secondDict=inputTree[firstStr] #获得子集\n",
    "    featIndex=featLabels.index(firstStr)\n",
    "    for key in secondDict.keys():\n",
    "        if testVec[featIndex]==key:\n",
    "            if type(secondDict[key]).__name__=='dict': #若子集非叶子节点，则遍历\n",
    "                classLabel=calssify(secondDict[key],featLabels,testVec)\n",
    "            else: #叶子节点，返回结果\n",
    "                classLabel=secondDict[key]\n",
    "    return classLabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：py3中 firstStr=inputTree.keys()[0] 这句代码报错如下：  \n",
    "'dict_keys' object does not support indexing  \n",
    "在python2.x中，dict.keys()返回一个列表，在python3.x中，dict.keys()返回一个dict_keys对象，比起列表，这个对象的行为更像是set，所以不支持索引的。  \n",
    "使用list(dict.keys())[index]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def storeTree(inputTree,filename):\n",
    "    import pickle\n",
    "    fw=open(filename,'w')\n",
    "    pickle.dump(inputTree,fw)\n",
    "    fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grabTree(filename):\n",
    "    import pickle\n",
    "    fr=open(filename)\n",
    "    return pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['young', 'myope', 'no', 'reduced', 'no lenses'], ['young', 'myope', 'no', 'normal', 'soft'], ['young', 'myope', 'yes', 'reduced', 'no lenses'], ['young', 'myope', 'yes', 'normal', 'hard'], ['young', 'hyper', 'no', 'reduced', 'no lenses'], ['young', 'hyper', 'no', 'normal', 'soft'], ['young', 'hyper', 'yes', 'reduced', 'no lenses'], ['young', 'hyper', 'yes', 'normal', 'hard'], ['pre', 'myope', 'no', 'reduced', 'no lenses'], ['pre', 'myope', 'no', 'normal', 'soft'], ['pre', 'myope', 'yes', 'reduced', 'no lenses'], ['pre', 'myope', 'yes', 'normal', 'hard'], ['pre', 'hyper', 'no', 'reduced', 'no lenses'], ['pre', 'hyper', 'no', 'normal', 'soft'], ['pre', 'hyper', 'yes', 'reduced', 'no lenses'], ['pre', 'hyper', 'yes', 'normal', 'no lenses'], ['presbyopic', 'myope', 'no', 'reduced', 'no lenses'], ['presbyopic', 'myope', 'no', 'normal', 'no lenses'], ['presbyopic', 'myope', 'yes', 'reduced', 'no lenses'], ['presbyopic', 'myope', 'yes', 'normal', 'hard'], ['presbyopic', 'hyper', 'no', 'reduced', 'no lenses'], ['presbyopic', 'hyper', 'no', 'normal', 'soft'], ['presbyopic', 'hyper', 'yes', 'reduced', 'no lenses'], ['presbyopic', 'hyper', 'yes', 'normal', 'no lenses']]\n",
      "{'tearRate': {'reduced': 'no lenses', 'normal': {'astigmatic': {'yes': {'prescript': {'myope': 'hard', 'hyper': {'age': {'presbyopic': 'no lenses', 'young': 'hard', 'pre': 'no lenses'}}}}, 'no': {'age': {'presbyopic': {'prescript': {'myope': 'no lenses', 'hyper': 'soft'}}, 'young': 'soft', 'pre': 'soft'}}}}}}\n"
     ]
    }
   ],
   "source": [
    "fr=open('lenses.txt')\n",
    "lenses=[inst.strip().split('\\t') for inst in fr.readlines()]\n",
    "print(lenses)\n",
    "lensesLabels=['age','prescript','astigmatic','tearRate']\n",
    "lensesTree=createTree(lenses,lensesLabels)\n",
    "print(lensesTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no lenses\n"
     ]
    }
   ],
   "source": [
    "lensesLabels=['age','prescript','astigmatic','tearRate']\n",
    "result=classify(lensesTree,lensesLabels,['young','myope','yes','reduced'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
