# DecisionTree
《机器学习实战》第三章——记录

#### 决策树分类算法原理
决策树是根据不同的属性值将数据集划分而成的一棵树，其中树中的每个叶子节点表示分类的结果，非叶子节点表示决策的依据。  

决策树主要包含构建决策树和使用决策树两部分：  

##### 1、构建决策树 （PS：书中使用ID3算法作为划分数据集的依据）
1.1、得到原始的数据集  
1.2、基于最好的属性划分数据集：即遍历当前特征中的所有唯一属性值，对每个特征划分一次数据集，然后计算数据集的新熵值，并对所有唯一特征值得到的熵值求和。并与原始数据集的香农熵比较，得到信息增益最大的属性值。即 MAX（原始香农熵-每个唯一特征值划分后的熵值和）。就是所求的“最好属性”。  
1.3、采用递归的原则再次划分数据集  
1.4、递归结束的条件是：程序遍历所有划分数据集的属性 或 每个分支下的所有实例都具有相同的分类。  

##### 2、使用决策树
比较测试数据与决策树上的数值，递归执行该过程知道进入叶子节点，最后将测试数据定义为叶子节点所属的类型。


